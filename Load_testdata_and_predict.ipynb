{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "import csv\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, TransformerWordEmbeddings, FlairEmbeddings, CharacterEmbeddings, OneHotEmbeddings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 12:40:42,758 loading file Model/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "#Load Model\n",
    "model_path = \"Model/best-model.pt\"\n",
    "model = SequenceTagger.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Testdata\n",
    "testdata_path = \"Data/testdata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we <B_C> will rock you\n"
     ]
    }
   ],
   "source": [
    "# Tagging Beispiel\n",
    "sentence = Sentence('we will rock you')\n",
    "model.predict(sentence)\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testdata_path,'r', encoding='utf8') as infile:\n",
    "    example_data = json.load(infile)\n",
    "\n",
    "\n",
    "for i,(k,v) in enumerate(example_data.items()):\n",
    "    tokens = v.get('tokens')\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    example_data[k]['tokens'] = tokens\n",
    "    \n",
    "all_tokens = [v['tokens'] for k,v in example_data.items()]\n",
    "all_labels = [v['labels'] for k,v in example_data.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"Data/Modified/modified_test.txt\"):\n",
    "  os.remove(\"Data/Modified/modified_test.txt\")\n",
    "else:\n",
    "  print(\"The file does not exist\")\n",
    "\n",
    "f = open(\"Data/Modified/modified_test.txt\", \"x\")\n",
    "\n",
    "for x in range(0, len(all_tokens)):\n",
    "    for y in range(0, len(all_tokens[x])):\n",
    "        new_line = all_tokens[x][y] + \" \" + all_labels[x][y] + \"\\n\"\n",
    "        f.write(new_line)\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 12:42:16,265 Reading data from .\n",
      "2020-10-22 12:42:16,267 Train: Data/Modified/dummy.txt\n",
      "2020-10-22 12:42:16,268 Dev: Data/Modified/dummy.txt\n",
      "2020-10-22 12:42:16,270 Test: Data/Modified/modified_test.txt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "# define columns\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = './'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='Data/Modified/dummy.txt',\n",
    "                              test_file='Data/Modified/modified_test.txt',\n",
    "                              dev_file='Data/Modified/dummy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary with 20 tags: <unk>, O, B_C, B_E, B_P, I_P, I_E, B_M, I_M, B_A, B_T, I_T, B_V, I_V, B_W, I_C, I_A, I_W, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, TransformerWordEmbeddings, FlairEmbeddings, CharacterEmbeddings, OneHotEmbeddings\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'<unk>']\n",
      "vocabulary size of 1\n"
     ]
    }
   ],
   "source": [
    "embedding_types = [\n",
    "\n",
    "    #WordEmbeddings('glove'),\n",
    "    OneHotEmbeddings(corpus),\n",
    "    # TransformerWordEmbeddings(\"bert-base-uncased\"),\n",
    "    # comment in this line to use character embeddings\n",
    "    #CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    #FlairEmbeddings('news-forward'),\n",
    "    #FlairEmbeddings('news-backward'),\n",
    "    #ELMoEmbeddings('medium')\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256, #256, 512\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        #loss_weights = weight_dict,\n",
    "                                        rnn_layers = 2, #Number of rnn_layers\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 12:20:31,161 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:20:31,163 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): OneHotEmbeddings(\n",
      "      min_freq=3\n",
      "      (embedding_layer): Embedding(1, 300)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (rnn): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=15, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-10-22 12:20:31,166 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:20:31,167 Corpus: \"Corpus: 1 train + 1 dev + 26 test sentences\"\n",
      "2020-10-22 12:20:31,169 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:20:31,171 Parameters:\n",
      "2020-10-22 12:20:31,172  - learning_rate: \"0.0\"\n",
      "2020-10-22 12:20:31,174  - mini_batch_size: \"32\"\n",
      "2020-10-22 12:20:31,176  - patience: \"3\"\n",
      "2020-10-22 12:20:31,177  - anneal_factor: \"0.5\"\n",
      "2020-10-22 12:20:31,179  - max_epochs: \"0\"\n",
      "2020-10-22 12:20:31,181  - shuffle: \"True\"\n",
      "2020-10-22 12:20:31,183  - train_with_dev: \"False\"\n",
      "2020-10-22 12:20:31,185  - batch_growth_annealing: \"False\"\n",
      "2020-10-22 12:20:31,186 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:20:31,188 Model training base path: \"Model\"\n",
      "2020-10-22 12:20:31,190 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:20:31,192 Device: cpu\n",
      "2020-10-22 12:20:31,193 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:20:31,195 Embeddings storage mode: cpu\n",
      "2020-10-22 12:20:31,239 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-22 12:20:31,242 Testing using best model ...\n",
      "2020-10-22 12:20:31,245 loading file Model/best-model.pt\n",
      "2020-10-22 12:20:45,659 \t0.9602\n",
      "2020-10-22 12:20:45,661 \n",
      "Results:\n",
      "- F-score (micro) 0.9602\n",
      "- F-score (macro) 0.177\n",
      "- Accuracy 0.9602\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         B_A     1.0000    0.0000    0.0000         1\n",
      "           O     0.9681    0.9940    0.9809       336\n",
      "         I_A     1.0000    0.0000    0.0000         1\n",
      "         B_T     1.0000    0.0000    0.0000         1\n",
      "         I_T     1.0000    0.0000    0.0000         1\n",
      "         B_W     1.0000    0.0000    0.0000         1\n",
      "         I_W     1.0000    0.0000    0.0000         1\n",
      "         B_C     0.6667    0.5000    0.5714         4\n",
      "         B_E     0.5000    0.6667    0.5714         3\n",
      "         B_P     1.0000    0.0000    0.0000         1\n",
      "         I_P     1.0000    0.0000    0.0000         1\n",
      "         I_E     1.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9602       352\n",
      "   macro avg     0.9279    0.1801    0.1770       352\n",
      "weighted avg     0.9615    0.9602    0.9477       352\n",
      "\n",
      "2020-10-22 12:20:45,663 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.9602,\n",
       " 'dev_score_history': [],\n",
       " 'train_loss_history': [],\n",
       " 'dev_loss_history': []}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy Training für Testdatenprognose\n",
    "trainer.train('Model',\n",
    "              learning_rate=0.0,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=0,\n",
    "              train_with_dev = \"False\", #Vorsicht-> eigentlich False\n",
    "             embeddings_storage_mode = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results= \"Model/test.tsv\"\n",
    "tsv_file = open(test_results)\n",
    "tsv_data = csv.reader(tsv_file, delimiter =\" \")\n",
    "test_data = []\n",
    "end = ['END', 'END', 'END']\n",
    "\n",
    "for row in tsv_data:\n",
    "    if not row:\n",
    "        test_data.append(end)\n",
    "    else:\n",
    "        test_data.append(row)\n",
    "\n",
    "tsv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens =[]\n",
    "labels =[]\n",
    "predicted = []\n",
    "predicted_list = []\n",
    "label_list = []\n",
    "token_list = []\n",
    "\n",
    "for token in test_data:\n",
    "    if token == end:\n",
    "        token_list.append(tokens)\n",
    "        label_list.append(labels)\n",
    "        predicted_list.append(predicted)\n",
    "        tokens =[]\n",
    "        labels =[]\n",
    "        predicted = []\n",
    "    else:\n",
    "        tokens.append(token[0])\n",
    "        labels.append(token[1])\n",
    "        predicted.append(token[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = token_list\n",
    "test_labels = label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelclass_to_id={'O':0,\n",
    "'B_C':1,'I_C':2, # 'companionship'\n",
    "'B_T':3,'I_T':4, # 'time'\n",
    "'B_W':5,'I_W':6, # 'weather'\n",
    "'B_P':7,'I_P':8, # 'position'\n",
    "'B_M':9,'I_M':10, # 'motivation'\n",
    "'B_E':11,'I_E':12, # 'emotional_state'\n",
    "'B_A':13,'I_A':14, # 'activity'\n",
    "'B_V':15,'I_V':16# 'visited_before'\n",
    "}\n",
    "\n",
    "max_seq_length = 120\n",
    "n_tags = len(list(labelclass_to_id.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Labels: 12 -> ['B_A', 'B_C', 'B_E', 'B_P', 'B_T', 'B_W', 'I_A', 'I_E', 'I_P', 'I_T', 'I_W', 'O']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predicted_list_flat = [item for sublist in predicted_list for item in sublist]\n",
    "label_list_flat = [item for sublist in label_list for item in sublist]\n",
    "y_pred = predicted_list_flat\n",
    "y_true = label_list_flat\n",
    "\n",
    "\n",
    "labels = list(set(y_true))\n",
    "labels.sort()\n",
    "\n",
    "print(\"Anzahl der Labels: %s -> %s\" % (len(labels), labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_A</th>\n",
       "      <th>B_C</th>\n",
       "      <th>B_E</th>\n",
       "      <th>B_P</th>\n",
       "      <th>B_T</th>\n",
       "      <th>B_W</th>\n",
       "      <th>I_A</th>\n",
       "      <th>I_E</th>\n",
       "      <th>I_P</th>\n",
       "      <th>I_T</th>\n",
       "      <th>I_W</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B_A</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_C</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_E</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_P</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_T</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_W</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I_A</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I_E</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I_P</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I_T</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I_W</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     B_A  B_C  B_E  B_P  B_T  B_W  I_A  I_E  I_P  I_T  I_W    O\n",
       "B_A    0    0    0    0    0    0    0    0    0    0    0    1\n",
       "B_C    0    2    0    0    0    0    0    0    0    0    0    2\n",
       "B_E    0    0    2    0    0    0    0    0    0    0    0    1\n",
       "B_P    0    0    0    0    0    0    0    0    0    0    0    1\n",
       "B_T    0    0    0    0    0    0    0    0    0    0    0    1\n",
       "B_W    0    0    0    0    0    0    0    0    0    0    0    1\n",
       "I_A    0    0    0    0    0    0    0    0    0    0    0    1\n",
       "I_E    0    0    1    0    0    0    0    0    0    0    0    0\n",
       "I_P    0    0    0    0    0    0    0    0    0    0    0    1\n",
       "I_T    0    0    0    0    0    0    0    0    0    0    0    1\n",
       "I_W    0    0    0    0    0    0    0    0    0    0    0    1\n",
       "O      0    1    1    0    0    0    0    0    0    0    0  334"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=confusion_matrix(y_true, y_pred, labels=labels),\n",
    "    columns=labels,\n",
    "    index=labels\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 12 is out of bounds for axis 0 with size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-6d9fc3215350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrecall_per_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mconf_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprecision_per_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mrecall_per_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 12 is out of bounds for axis 0 with size 12"
     ]
    }
   ],
   "source": [
    "# compute final evaluation measures\n",
    "precision_per_class = np.zeros((n_tags,))\n",
    "recall_per_class = np.zeros((n_tags,))\n",
    "for i in range(n_tags):\n",
    "    if conf_matrix.values[i,i] > 0:\n",
    "        precision_per_class[i] = conf_matrix.values[i,i]/sum(conf_matrix.values[:,i])\n",
    "        recall_per_class[i] = conf_matrix.values[i,i]/sum(conf_matrix.values[i,:])\n",
    "precision = np.mean(precision_per_class)\n",
    "recall = np.mean(recall_per_class)\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print('Precision: '+str(precision))\n",
    "print('Recall: '+str(recall))\n",
    "print('F1-measure: '+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
